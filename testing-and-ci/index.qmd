---
author: Patrick J. Roddy
date: 2025-12-03
format: revealjs
subtitle: "[CCMI CDT: Software Engineering Fundamentals](https://ccmi-cdt.org)"
title: Testing and CI
---

{{< include /_includes/qr-code.qmd >}}

# Testing

<!-- vale RedHat.TermsWarnings = NO -->

## Unit Tests {data-menu-title="Unit Tests (i)"}

<!-- vale RedHat.TermsWarnings = YES -->

- Low level
- Close to the source of the application
- Tests individual methods/functions
- Cheap to automate
- Run quickly

## Example {data-menu-title="Unit Tests (ii)"}

```{.python}
def add(a, b):
    return a + b

def test_add_positive_numbers():
    assert add(2, 3) == 5

def test_add_negative_numbers():
    assert add(-1, -1) == -2
```

## Example {data-menu-title="Unit Tests (iii)"}

```{.python}
import pytest

def divide(a, b):
    if b == 0:
        raise ValueError("Cannot divide by zero")
    return a / b

def test_divide_by_zero_raises_error():
    with pytest.raises(ValueError, match="Cannot divide by zero"):
        divide(10, 0)

@pytest.mark.parametrize(
    "a,b,expected",
    [
        (10, 2, 5),
        (20, 4, 5),
        (100, 10, 10),
    ],
)
def test_divide_various_inputs(a, b, expected):
    assert divide(a, b) == expected
```

<!-- vale RedHat.TermsWarnings = NO -->

## Integration Tests {data-menu-title="Integration Tests (i)"}

<!-- vale RedHat.TermsWarnings = YES -->

- Verifies that different part of the application work well together
- e.g. test interaction with database/make sure microservices work together
- More expensive to run
- Many parts of the application need to be up and running

## Integration Tests {data-menu-title="Integration Tests (ii)"}

```{.python}
import pytest
from sqlalchemy import create_engine
from myapp.repository import UserRepository

@pytest.fixture
def db_engine():
    """Create in-memory database for testing"""
    engine = create_engine("sqlite:///:memory:")
    yield engine
    engine.dispose()

@pytest.fixture
def user_repo(db_engine):
    """Create repository with test database"""
    repo = UserRepository(db_engine)
    repo.create_tables()
    return repo
```

## Integration Tests {data-menu-title="Integration Tests (iii)"}

```{.python}
from myapp.models import User

def test_create_and_retrieve_user(user_repo):
    # Test that we can save to database and retrieve
    user = User(name="Alice", email="alice@example.com")
    user_id = user_repo.save(user)

    retrieved_user = user_repo.get_by_id(user_id)
    assert retrieved_user.name == "Alice"
    assert retrieved_user.email == "alice@example.com"

def test_update_user_email(user_repo):
    user = User(name="Bob", email="bob@example.com")
    user_id = user_repo.save(user)

    user_repo.update_email(user_id, "newemail@example.com")
    updated_user = user_repo.get_by_id(user_id)

    assert updated_user.email == "newemail@example.com"
```

<!-- vale RedHat.TermsWarnings = NO -->

## Functional Tests {data-menu-title="Functional Tests (i)"}

<!-- vale RedHat.TermsWarnings = YES -->

- Focus on business requirements of application
- Only verify the output of an action
- In comparison to an integration test it would be a specific value from the
  database rather than just the connection

## Example {data-menu-title="Functional Tests (ii)"}

<!-- vale RedHat.TermsWarnings = NO -->

## End-to-End Tests {data-menu-title="End-to-End Tests (i)"}

<!-- vale RedHat.TermsWarnings = YES -->

- Replicates user behaviour in a complete application environment
- Verifies that user flows work as expected
- Can be as simple loading a web page
- Expensive to perform
- Hard to support when automated
- Only need a few

## End-to-End Tests {data-menu-title="End-to-End Tests (ii)"}

<!-- vale RedHat.TermsWarnings = NO -->

## Acceptance Testing {data-menu-title="Acceptance Tests (i)"}

<!-- vale RedHat.TermsWarnings = YES -->

- Formal tests that verify if a system satisfies business requirements
- Require entire application to be running while testing
- Replicate user behaviours
- Can also measure the performance, reject if certain goals not met

## Acceptance Testing {data-menu-title="Acceptance Tests (ii)"}

<!-- vale RedHat.TermsWarnings = NO -->

## Performance Testing {data-menu-title="Performance Tests (i)"}

<!-- vale RedHat.TermsWarnings = YES -->

- Evaluate how a system performs under a particular workload
- Help measure reliability, speed, scalability, responsiveness
- e.g. observe response times when executing a high number of requests
- Determines if an application meets performance requirements

## Performance Testing {data-menu-title="Performance Tests (ii)"}

<!-- vale RedHat.TermsWarnings = NO -->

## Smoke Testing {data-menu-title="Smoke Tests (i)"}

<!-- vale RedHat.TermsWarnings = YES -->

- Basic tests that check the basic functionality of an application
- Meant to be quick to run
- Goal to give the assurance that major features are working as expected
- Useful after a new build to decide whether to run more expensive tests
- Or after a deployment to make sure application is running in the new environment

## Smoke Testing {data-menu-title="Smoke Tests (ii)"}

## Miscellaneous

- Mutation Testing
- Mocking
